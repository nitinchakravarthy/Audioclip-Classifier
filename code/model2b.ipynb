{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_DATA_PATH = \"./speech/data/\"\n",
    "\n",
    "URBAN_NOISE_DATA_PATH = \"./urban/data/\"\n",
    "\n",
    "COMBINED_DATA_PATH = \"./combined/data/\"\n",
    "\n",
    "SPEECH_NPY_PATH = \"./40bins_allfeat/npy/\"\n",
    "_\n",
    "URBAN_NOISE_NPY_PATH = \"./40bins_allfeat/npy/\"\n",
    "\n",
    "COMBINED_NPY_PATH =  \"./combined/40bins_allfeat/npy/\"\n",
    "\n",
    "COMBINED_MODEL_SAVE_PATH = \"./models/40bins__allfeat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech test and val file paths\n",
    "testFile = \"./data/testing_list.txt\"\n",
    "valFile = \"./data/validation_list.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to convert wav2mfcc\n",
    "# samp rate of the speech wav files is 16000\n",
    "# samp rate of the urban noise wav files is 8000\n",
    "# use the samprate argument to change that.... will downsample speech wav files to 8000 in the future to make it easier\n",
    "def wav2mfcc(file_path, max_len=11,samprate = 8000):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    ##mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=40)\n",
    "    melspectrogram =librosa.feature.melspectrogram(y=wave, sr=sr, n_mels=40,fmax=10000)\n",
    "    chroma_stft=librosa.feature.chroma_stft(y=wave, sr=sr,n_chroma=40)\n",
    "    chroma_cq =librosa.feature.chroma_cqt(y=wave, sr=sr,n_chroma=40)\n",
    "    chroma_cens =librosa.feature.chroma_cens(y=wave, sr=sr,n_chroma=40)\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]   \n",
    "        \n",
    "    if (max_len > melspectrogram.shape[1]):\n",
    "        pad_width = max_len - melspectrogram.shape[1]\n",
    "        melspectrogram = np.pad(melspectrogram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        melspectrogram = melspectrogram[:, :max_len]   \n",
    "        \n",
    "    if (max_len > chroma_stft.shape[1]):\n",
    "        pad_width = max_len - chroma_stft.shape[1]\n",
    "        chroma_stft = np.pad(chroma_stft, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        chroma_stft = chroma_stft[:, :max_len]   \n",
    "\n",
    "        \n",
    "    if (max_len > chroma_cq.shape[1]):\n",
    "        pad_width = max_len - chroma_cq.shape[1]\n",
    "        chroma_cq = np.pad(chroma_cq, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        chroma_cq = chroma_cq[:, :max_len]   \n",
    "        \n",
    "    if (max_len > chroma_cens.shape[1]):\n",
    "        pad_width = max_len - chroma_cens.shape[1]\n",
    "        chroma_cens = np.pad(chroma_cens, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        chroma_cens = chroma_cens[:, :max_len]   \n",
    "    # Else cutoff the remaining parts\n",
    "    features=np.stack((mfcc,melspectrogram,chroma_stft,chroma_cq,chroma_cens),axis=2)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/librosa/filters.py:284: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 11, 5)\n"
     ]
    }
   ],
   "source": [
    "mfcc = wav2mfcc(\"/media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/speech/data/bed/00176480_nohash_0.wav\")\n",
    "print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "# make sure the background noise folder is not insde the DATA_PATH. because that is used for data augmentation and not recognition\n",
    "def get_labels(path=COMBINED_DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the save data code here....with test train and val split\n",
    "# make sure the background_noise folder is not in the path\n",
    "def save_data_speech(path = SPEECH_DATA_PATH, testFile = testFile, valFile = valFile, max_len = 11,savepath = SPEECH_NPY_PATH):\n",
    "\n",
    "    test_file = open(testFile, \"r\")\n",
    "    testFilesList = test_file.read().split('\\n')\n",
    "\n",
    "    val_file = open(valFile, \"r\")\n",
    "    valFilesList = val_file.read().split('\\n')\n",
    "\n",
    "    #print(testFilesList)\n",
    "    #print(valFilesList)\n",
    "    labels,_,_ = get_labels(path)\n",
    "    print(labels)\n",
    "    for label in labels:\n",
    "        mfcc_train = []\n",
    "        mfcc_test = []\n",
    "        mfcc_val = []\n",
    "        # saving a tuple of wavfile path and label/name format to compare in the test and val list\n",
    "        wavfiles = [(path + label + '/' + wavfile, label + '/' + wavfile)\n",
    "                    for wavfile in os.listdir(path + '/' + label)]\n",
    "        \n",
    "        #print(wavfiles)\n",
    "        \n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            #print(wavfile[0])\n",
    "            #print(wavfile[1])\n",
    "            mfcc = wav2mfcc(wavfile[0], max_len=max_len)\n",
    "            #print(mfcc.shape)\n",
    "            if wavfile[1] in testFilesList:\n",
    "                mfcc_test.append(mfcc)\n",
    "            elif wavfile[1] in valFilesList:\n",
    "                mfcc_val.append(mfcc)\n",
    "            else:\n",
    "                mfcc_train.append(mfcc)\n",
    "                \n",
    "        np.save(savepath + label + '_test.npy', mfcc_test)\n",
    "        np.save(savepath + label + '_val.npy', mfcc_val)\n",
    "        np.save(savepath + label + '_train.npy', mfcc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just saving the urban data as the npy file.\n",
    "# will split the data into test train and val after loading the data nd the labels by using a test_train split function\n",
    "def save_urbanNoise_data(path = URBAN_NOISE_DATA_PATH, max_len = 11, savePath = URBAN_NOISE_NPY_PATH):\n",
    "    labels,_,_ = get_labels(path)\n",
    "    for label in labels:\n",
    "        mfccs = []\n",
    "        mfcc_train = []\n",
    "        mfcc_test = []\n",
    "        mfcc_val = []\n",
    "        print(label)\n",
    "        \n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        \n",
    "        for wavfile in tqdm(wavfiles, \"saving vectors of label - '{}'\".format(label)):\n",
    "            try:\n",
    "                mfcc = wav2mfcc(wavfile, max_len = max_len)\n",
    "                mfccs.append(mfcc)\n",
    "            except:\n",
    "                print(wavfile)\n",
    "        \n",
    "        np.save(savePath + label + '.npy', mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 40      #max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# speech data\n",
    "save_data_speech(max_len = feature_dim_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#urban Noise data\n",
    "save_urbanNoise_data(max_len = feature_dim_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the urbanNoiseData along with their labels then split them into train,val and split and save as npy files\n",
    "# we will get all the data from all the classes append them into an array and then use a test train split function\n",
    "def getUrbanNoiseDataSplit(path = URBAN_NOISE_DATA_PATH, savePath = URBAN_NOISE_NPY_PATH, split_ratio=0.8,random_state = 42):\n",
    "    labels, indices, _ = get_labels(path)\n",
    "    # get the array for each label\n",
    "    X = np.load(savePath + labels[0] + '.npy')\n",
    "    Y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    # filling with i+1 in each loop so basically starting the class values from 0 to 9.\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(savePath + label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        Y = np.append(Y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(Y)\n",
    "    \n",
    "    # not shuffling the data for now. Will shuffle them while training\n",
    "    X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_temp,Y_temp, test_size = (1-split_ratio), random_state = random_state,shuffle = True)\n",
    "    \n",
    "    return labels,X_train,X_val,X_test,Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speech we already split the data into train test and val and then saved the data. \n",
    "# so now we just need to import the data and then append all the labels\n",
    "def getSpeechDataSplit(path = SPEECH_DATA_PATH, savePath = SPEECH_NPY_PATH):\n",
    "    \n",
    "    labels, indices, _ = get_labels(path)\n",
    "    # get the array for each label\n",
    "    X_train = np.load(savePath + labels[0] + '_train.npy')\n",
    "    Y_train = np.zeros(X_train.shape[0])\n",
    "    X_val = np.load(savePath + labels[0] + '_val.npy')\n",
    "    Y_val = np.zeros(X_val.shape[0])\n",
    "    X_test = np.load(savePath + labels[0] + '_test.npy')\n",
    "    Y_test = np.zeros(X_test.shape[0])\n",
    "    \n",
    "    for i,label in enumerate(labels[1:]):\n",
    "        x_train = np.load(savePath + label + '_train.npy')\n",
    "        x_val = np.load(savePath + label + '_val.npy')\n",
    "        x_test = np.load(savePath + label + '_test.npy')\n",
    "        X_train = np.vstack((X_train, x_train))\n",
    "        X_val = np.vstack((X_val, x_val))\n",
    "        X_test = np.vstack((X_test, x_test))\n",
    "        \n",
    "        Y_train = np.append(Y_train, np.full(x_train.shape[0],fill_value= (i+1)))\n",
    "        Y_val = np.append(Y_val, np.full(x_val.shape[0],fill_value= (i+1)))\n",
    "        Y_test = np.append(Y_test, np.full(x_test.shape[0],fill_value= (i+1)))\n",
    "    \n",
    "        \n",
    "    return labels,X_train,X_val,X_test,Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['air_conditioner', 'dog_bark', 'street_music', 'car_horn', 'drilling', 'children_playing', 'siren', 'engine_idling', 'jackhammer', 'gun_shot']\n"
     ]
    }
   ],
   "source": [
    "# # Loading train set and test set of urban Noise\n",
    "labels_un, X_train_un,X_val_un, X_test_un, Y_train_un,Y_val_un, Y_test_un = getUrbanNoiseDataSplit()\n",
    "print(labels_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'learn', 'right', 'nine', 'eight', 'dog', 'bird', 'house', 'marvin', 'zero', 'sheila', 'bed', 'follow', 'off', 'happy', 'backward', 'on', 'cat', 'left', 'five', 'visual', 'one', 'no', 'two', 'yes', 'forward', 'tree', 'three', 'go', 'seven', 'six', 'wow', 'stop', 'four', 'up']\n"
     ]
    }
   ],
   "source": [
    "# # Loading train set and test set of speech\n",
    "labels_sp, X_train_sp,X_val_sp, X_test_sp, Y_train_sp,Y_val_sp, Y_test_sp = getSpeechDataSplit()\n",
    "print(labels_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5579, 40, 40, 5),\n",
       " (1395, 40, 40, 5),\n",
       " (1744, 40, 40, 5),\n",
       " (5579,),\n",
       " (1395,),\n",
       " (1744,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shapes of all arrays\n",
    "X_train_un.shape,X_val_un.shape, X_test_un.shape, Y_train_un.shape,Y_val_un.shape, Y_test_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84843, 40, 40, 5),\n",
       " (9981, 40, 40, 5),\n",
       " (11005, 40, 40, 5),\n",
       " (84843,),\n",
       " (9981,),\n",
       " (11005,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sp.shape,X_val_sp.shape, X_test_sp.shape, Y_train_sp.shape,Y_val_sp.shape, Y_test_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "# if we want to combine both the samples we just need to add the Y sample with the numeber of labels in the previous dataset\n",
    "\n",
    "# combining samples\n",
    "labels = labels_sp + labels_un\n",
    "print(len(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add 35 to the urban Noise Y data to make them into the new labels\n",
    "\n",
    "\n",
    "Y_train_un_new = Y_train_un + 35\n",
    "Y_test_un_new = Y_test_un + 35\n",
    "Y_val_un_new = Y_val_un + 35\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90422,)\n",
      "(12749,)\n",
      "(11376,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.append(Y_train_sp, Y_train_un_new)\n",
    "Y_test = np.append(Y_test_sp, Y_test_un_new)\n",
    "Y_val = np.append(Y_val_sp, Y_val_un_new)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ... 39. 37. 38.]\n",
      "[ 0.  0.  0. ... 37. 39. 40.]\n",
      "[ 0.  0.  0. ... 38. 44. 36.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "print(Y_train)\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90422, 40, 40, 5)\n",
      "(12749, 40, 40, 5)\n",
      "(11376, 40, 40, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack((X_train_sp, X_train_un))\n",
    "X_test = np.vstack((X_test_sp, X_test_un))\n",
    "X_val = np.vstack((X_val_sp, X_val_un))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have combined data set and seperate datasets\n",
    "# X_train_un, X_test_un, X_val_un, Y_train_un, Y_test_un, Y_val_un ---urban Noise data - 10 clasees - (0-9)\n",
    "# X_train_sp, X_test_sp, X_val_sp, Y_train_sp, Y_test_sp, Y_val_sp --- speech data - 35 classes - (0-34)\n",
    "# X_train, X_test, X_val, Y_train, Y_test, Y_val --- combined dtat - 45 classes (0-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature dimension\n",
    "feature_dim_1 = 40\n",
    "channel = 5\n",
    "epochs = 200\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 45    #keeps changing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to perform 2D convolution\n",
    "# all data\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_val = X_val.reshape(X_val.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "Y_train_hot = to_categorical(Y_train)\n",
    "Y_val_hot = to_categorical(Y_val)\n",
    "Y_test_hot = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90422, 40, 40, 5)\n",
      "(12749, 40, 40, 5)\n",
      "(11376, 40, 40, 5)\n",
      "(90422, 45)\n",
      "(12749, 45)\n",
      "(11376, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "print(Y_train_hot.shape)\n",
    "print(Y_test_hot.shape)\n",
    "print(Y_val_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 90422 samples, validate on 12749 samples\n",
      "Epoch 1/200\n",
      "  500/90422 [..............................] - ETA: 2:08:42 - loss: 3.9350 - acc: 0.0280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.298519). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90422/90422 [==============================] - 85s 940us/step - loss: 2.7526 - acc: 0.2221 - val_loss: 1.6007 - val_acc: 0.4985\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49847, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-01-0.50.hdf5\n",
      "Epoch 2/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 1.5773 - acc: 0.5317 - val_loss: 1.1057 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49847 to 0.66311, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-02-0.66.hdf5\n",
      "Epoch 3/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 1.2526 - acc: 0.6365 - val_loss: 0.9169 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.66311 to 0.72963, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-03-0.73.hdf5\n",
      "Epoch 4/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 1.0949 - acc: 0.6866 - val_loss: 0.8542 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72963 to 0.74327, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-04-0.74.hdf5\n",
      "Epoch 5/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 1.0013 - acc: 0.7155 - val_loss: 0.7886 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74327 to 0.77088, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-05-0.77.hdf5\n",
      "Epoch 6/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.9365 - acc: 0.7345 - val_loss: 0.7883 - val_acc: 0.7698\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77088\n",
      "Epoch 7/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 0.8897 - acc: 0.7500 - val_loss: 0.7661 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.77088 to 0.77661, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-07-0.78.hdf5\n",
      "Epoch 8/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.8538 - acc: 0.7611 - val_loss: 0.7078 - val_acc: 0.7941\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77661 to 0.79410, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-08-0.79.hdf5\n",
      "Epoch 9/200\n",
      "90422/90422 [==============================] - 39s 432us/step - loss: 0.8209 - acc: 0.7703 - val_loss: 0.7783 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79410\n",
      "Epoch 10/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.7925 - acc: 0.7791 - val_loss: 0.6859 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79410 to 0.80649, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-10-0.81.hdf5\n",
      "Epoch 11/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.7649 - acc: 0.7853 - val_loss: 0.7102 - val_acc: 0.7964\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80649\n",
      "Epoch 12/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 0.7490 - acc: 0.7926 - val_loss: 0.6582 - val_acc: 0.8126\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80649 to 0.81261, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-12-0.81.hdf5\n",
      "Epoch 13/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.7334 - acc: 0.7942 - val_loss: 0.7121 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81261\n",
      "Epoch 14/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.7160 - acc: 0.8004 - val_loss: 0.6550 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.81261 to 0.81450, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-14-0.81.hdf5\n",
      "Epoch 15/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 0.7005 - acc: 0.8041 - val_loss: 0.6657 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.81450 to 0.81583, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-15-0.82.hdf5\n",
      "Epoch 16/200\n",
      "90422/90422 [==============================] - 39s 434us/step - loss: 0.6879 - acc: 0.8076 - val_loss: 0.6827 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81583\n",
      "Epoch 17/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.6850 - acc: 0.8086 - val_loss: 0.6450 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.81583 to 0.81936, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-17-0.82.hdf5\n",
      "Epoch 18/200\n",
      "90422/90422 [==============================] - 39s 434us/step - loss: 0.6740 - acc: 0.8123 - val_loss: 0.6533 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.81936\n",
      "Epoch 19/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.6581 - acc: 0.8180 - val_loss: 0.6919 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.81936\n",
      "Epoch 20/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.6614 - acc: 0.8168 - val_loss: 0.6310 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.81936 to 0.82610, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-20-0.83.hdf5\n",
      "Epoch 21/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.6363 - acc: 0.8237 - val_loss: 0.6726 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82610\n",
      "Epoch 22/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.6370 - acc: 0.8233 - val_loss: 0.6429 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82610\n",
      "Epoch 23/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.6287 - acc: 0.8254 - val_loss: 0.6452 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.82610\n",
      "Epoch 24/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.6204 - acc: 0.8278 - val_loss: 0.6392 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.82610 to 0.82830, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-24-0.83.hdf5\n",
      "Epoch 25/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.6246 - acc: 0.8263 - val_loss: 0.6561 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82830\n",
      "Epoch 26/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.6132 - acc: 0.8301 - val_loss: 0.6835 - val_acc: 0.8123\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82830\n",
      "Epoch 27/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.6064 - acc: 0.8324 - val_loss: 0.6486 - val_acc: 0.8289\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.82830 to 0.82893, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-27-0.83.hdf5\n",
      "Epoch 28/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.6065 - acc: 0.8309 - val_loss: 0.6676 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.82893 to 0.82932, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-28-0.83.hdf5\n",
      "Epoch 29/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.6016 - acc: 0.8349 - val_loss: 0.6559 - val_acc: 0.8259\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82932\n",
      "Epoch 30/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5979 - acc: 0.8344 - val_loss: 0.6513 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.82932 to 0.83065, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-30-0.83.hdf5\n",
      "Epoch 31/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5908 - acc: 0.8370 - val_loss: 0.6328 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83065\n",
      "Epoch 32/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5864 - acc: 0.8377 - val_loss: 0.6687 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83065\n",
      "Epoch 33/200\n",
      "90422/90422 [==============================] - 39s 436us/step - loss: 0.5880 - acc: 0.8384 - val_loss: 0.6259 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.83065 to 0.83363, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-33-0.83.hdf5\n",
      "Epoch 34/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5804 - acc: 0.8386 - val_loss: 0.6768 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.83363\n",
      "Epoch 35/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.5773 - acc: 0.8399 - val_loss: 0.6232 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.83363\n",
      "Epoch 36/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.5776 - acc: 0.8415 - val_loss: 0.6571 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83363\n",
      "Epoch 37/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.5714 - acc: 0.8430 - val_loss: 0.6685 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.83363 to 0.83481, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-37-0.83.hdf5\n",
      "Epoch 38/200\n",
      "90422/90422 [==============================] - 39s 432us/step - loss: 0.5680 - acc: 0.8424 - val_loss: 0.6697 - val_acc: 0.8327\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83481\n",
      "Epoch 39/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5682 - acc: 0.8433 - val_loss: 0.6598 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83481\n",
      "Epoch 40/200\n",
      "90422/90422 [==============================] - 39s 434us/step - loss: 0.5708 - acc: 0.8433 - val_loss: 0.7002 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83481\n",
      "Epoch 41/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5638 - acc: 0.8449 - val_loss: 0.6845 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83481\n",
      "Epoch 42/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5567 - acc: 0.8474 - val_loss: 0.6596 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.83481\n",
      "Epoch 43/200\n",
      "90422/90422 [==============================] - 39s 432us/step - loss: 0.5569 - acc: 0.8465 - val_loss: 0.6851 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.83481\n",
      "Epoch 44/200\n",
      "90422/90422 [==============================] - 39s 431us/step - loss: 0.5551 - acc: 0.8467 - val_loss: 0.6478 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.83481\n",
      "Epoch 45/200\n",
      "90422/90422 [==============================] - 39s 430us/step - loss: 0.5529 - acc: 0.8480 - val_loss: 0.6427 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.83481\n",
      "Epoch 46/200\n",
      "90422/90422 [==============================] - 39s 429us/step - loss: 0.5581 - acc: 0.8472 - val_loss: 0.6886 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83481\n",
      "Epoch 47/200\n",
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.5481 - acc: 0.8483 - val_loss: 0.6685 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.83481\n",
      "Epoch 48/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5512 - acc: 0.8488 - val_loss: 0.6942 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.83481\n",
      "Epoch 49/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5449 - acc: 0.8498 - val_loss: 0.6877 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83481\n",
      "Epoch 50/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5461 - acc: 0.8505 - val_loss: 0.6519 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83481 to 0.84038, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-50-0.84.hdf5\n",
      "Epoch 51/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5507 - acc: 0.8491 - val_loss: 0.6373 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.84038\n",
      "Epoch 52/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5494 - acc: 0.8504 - val_loss: 0.6473 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.84038\n",
      "Epoch 53/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5475 - acc: 0.8490 - val_loss: 0.6773 - val_acc: 0.8404\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84038 to 0.84038, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-53-0.84.hdf5\n",
      "Epoch 54/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5427 - acc: 0.8514 - val_loss: 0.7035 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.84038\n",
      "Epoch 55/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5429 - acc: 0.8519 - val_loss: 0.6846 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.84038\n",
      "Epoch 56/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5426 - acc: 0.8508 - val_loss: 0.6605 - val_acc: 0.8362\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.84038\n",
      "Epoch 57/200\n",
      "90422/90422 [==============================] - 40s 441us/step - loss: 0.5426 - acc: 0.8521 - val_loss: 0.6778 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.84038\n",
      "Epoch 58/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5377 - acc: 0.8546 - val_loss: 0.6653 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.84038\n",
      "Epoch 59/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5380 - acc: 0.8530 - val_loss: 0.6368 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.84038 to 0.84242, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-59-0.84.hdf5\n",
      "Epoch 60/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5401 - acc: 0.8535 - val_loss: 0.7318 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.84242\n",
      "Epoch 61/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5377 - acc: 0.8544 - val_loss: 0.6862 - val_acc: 0.8366\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.84242\n",
      "Epoch 62/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5330 - acc: 0.8534 - val_loss: 0.6628 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.84242\n",
      "Epoch 63/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5401 - acc: 0.8533 - val_loss: 0.6764 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.84242\n",
      "Epoch 64/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5345 - acc: 0.8543 - val_loss: 0.6969 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84242\n",
      "Epoch 65/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5284 - acc: 0.8555 - val_loss: 0.6918 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84242\n",
      "Epoch 66/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5324 - acc: 0.8560 - val_loss: 0.6878 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84242\n",
      "Epoch 67/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5356 - acc: 0.8558 - val_loss: 0.6691 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.84242\n",
      "Epoch 68/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5341 - acc: 0.8542 - val_loss: 0.6793 - val_acc: 0.8376\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.84242\n",
      "Epoch 69/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5295 - acc: 0.8557 - val_loss: 0.6594 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.84242\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5306 - acc: 0.8547 - val_loss: 0.6615 - val_acc: 0.8376\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.84242\n",
      "Epoch 71/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5362 - acc: 0.8544 - val_loss: 0.7005 - val_acc: 0.8320\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.84242\n",
      "Epoch 72/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5348 - acc: 0.8539 - val_loss: 0.7283 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.84242\n",
      "Epoch 73/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5317 - acc: 0.8565 - val_loss: 0.7142 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.84242\n",
      "Epoch 74/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5253 - acc: 0.8575 - val_loss: 0.6755 - val_acc: 0.8380\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.84242\n",
      "Epoch 75/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5388 - acc: 0.8553 - val_loss: 0.7140 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.84242\n",
      "Epoch 76/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5310 - acc: 0.8564 - val_loss: 0.6964 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.84242\n",
      "Epoch 77/200\n",
      "90422/90422 [==============================] - 40s 440us/step - loss: 0.5289 - acc: 0.8562 - val_loss: 0.7535 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.84242\n",
      "Epoch 78/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5297 - acc: 0.8569 - val_loss: 0.7455 - val_acc: 0.8278\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.84242\n",
      "Epoch 79/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5307 - acc: 0.8557 - val_loss: 0.7165 - val_acc: 0.8298\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.84242\n",
      "Epoch 80/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5299 - acc: 0.8575 - val_loss: 0.6896 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.84242\n",
      "Epoch 81/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5301 - acc: 0.8575 - val_loss: 0.7022 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.84242 to 0.84548, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/4040binsextra/all_data-81-0.85.hdf5\n",
      "Epoch 82/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5219 - acc: 0.8611 - val_loss: 0.6759 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.84548\n",
      "Epoch 83/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5293 - acc: 0.8570 - val_loss: 0.7062 - val_acc: 0.8389\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.84548\n",
      "Epoch 84/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5341 - acc: 0.8568 - val_loss: 0.6807 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.84548\n",
      "Epoch 85/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5266 - acc: 0.8576 - val_loss: 0.6824 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.84548\n",
      "Epoch 86/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5270 - acc: 0.8578 - val_loss: 0.7145 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.84548\n",
      "Epoch 87/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5324 - acc: 0.8574 - val_loss: 0.6689 - val_acc: 0.8318\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.84548\n",
      "Epoch 88/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5225 - acc: 0.8590 - val_loss: 0.6571 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.84548\n",
      "Epoch 89/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5198 - acc: 0.8595 - val_loss: 0.7579 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.84548\n",
      "Epoch 90/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5252 - acc: 0.8590 - val_loss: 0.7064 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.84548\n",
      "Epoch 91/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5294 - acc: 0.8584 - val_loss: 0.6770 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.84548\n",
      "Epoch 92/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5331 - acc: 0.8584 - val_loss: 0.7108 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.84548\n",
      "Epoch 93/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5314 - acc: 0.8579 - val_loss: 0.7507 - val_acc: 0.8234\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.84548\n",
      "Epoch 94/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5238 - acc: 0.8599 - val_loss: 0.7112 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.84548\n",
      "Epoch 95/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5262 - acc: 0.8603 - val_loss: 0.6851 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.84548\n",
      "Epoch 96/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5300 - acc: 0.8579 - val_loss: 0.7069 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.84548\n",
      "Epoch 97/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5296 - acc: 0.8580 - val_loss: 0.7281 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.84548\n",
      "Epoch 98/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5282 - acc: 0.8579 - val_loss: 0.6764 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.84548\n",
      "Epoch 99/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5387 - acc: 0.8563 - val_loss: 0.6591 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.84548\n",
      "Epoch 100/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5329 - acc: 0.8567 - val_loss: 0.6894 - val_acc: 0.8338\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.84548\n",
      "Epoch 101/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5253 - acc: 0.8590 - val_loss: 0.7623 - val_acc: 0.8362\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.84548\n",
      "Epoch 102/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5365 - acc: 0.8578 - val_loss: 0.6827 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.84548\n",
      "Epoch 103/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5305 - acc: 0.8578 - val_loss: 0.7466 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.84548\n",
      "Epoch 104/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5376 - acc: 0.8577 - val_loss: 0.6901 - val_acc: 0.8385\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.84548\n",
      "Epoch 105/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5331 - acc: 0.8571 - val_loss: 0.7438 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.84548\n",
      "Epoch 106/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5371 - acc: 0.8562 - val_loss: 0.6707 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.84548\n",
      "Epoch 107/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5260 - acc: 0.8591 - val_loss: 0.7730 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.84548\n",
      "Epoch 108/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5355 - acc: 0.8582 - val_loss: 0.7004 - val_acc: 0.8318\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.84548\n",
      "Epoch 109/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5363 - acc: 0.8574 - val_loss: 0.6695 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.84548\n",
      "Epoch 110/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5402 - acc: 0.8561 - val_loss: 0.8128 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.84548\n",
      "Epoch 111/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5431 - acc: 0.8558 - val_loss: 0.7524 - val_acc: 0.8399\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.84548\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90422/90422 [==============================] - 39s 435us/step - loss: 0.5346 - acc: 0.8570 - val_loss: 0.7276 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.84548\n",
      "Epoch 113/200\n",
      "90422/90422 [==============================] - 39s 434us/step - loss: 0.5360 - acc: 0.8580 - val_loss: 0.6778 - val_acc: 0.8292\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.84548\n",
      "Epoch 114/200\n",
      "90422/90422 [==============================] - 39s 433us/step - loss: 0.5282 - acc: 0.8577 - val_loss: 0.7906 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.84548\n",
      "Epoch 115/200\n",
      "90422/90422 [==============================] - 39s 434us/step - loss: 0.5437 - acc: 0.8569 - val_loss: 0.6700 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.84548\n",
      "Epoch 116/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5424 - acc: 0.8567 - val_loss: 0.6896 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.84548\n",
      "Epoch 117/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5340 - acc: 0.8589 - val_loss: 0.6856 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.84548\n",
      "Epoch 118/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5386 - acc: 0.8563 - val_loss: 0.7728 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.84548\n",
      "Epoch 119/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5429 - acc: 0.8566 - val_loss: 0.6824 - val_acc: 0.8388\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.84548\n",
      "Epoch 120/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5380 - acc: 0.8574 - val_loss: 0.7220 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.84548\n",
      "Epoch 121/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5454 - acc: 0.8560 - val_loss: 0.6665 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.84548\n",
      "Epoch 122/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5338 - acc: 0.8582 - val_loss: 0.7514 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.84548\n",
      "Epoch 123/200\n",
      "90422/90422 [==============================] - 40s 439us/step - loss: 0.5374 - acc: 0.8570 - val_loss: 0.7253 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.84548\n",
      "Epoch 124/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5424 - acc: 0.8566 - val_loss: 0.6695 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.84548\n",
      "Epoch 125/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5398 - acc: 0.8570 - val_loss: 0.7217 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.84548\n",
      "Epoch 126/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5412 - acc: 0.8574 - val_loss: 0.6853 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.84548\n",
      "Epoch 127/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5431 - acc: 0.8563 - val_loss: 0.6866 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.84548\n",
      "Epoch 128/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5438 - acc: 0.8564 - val_loss: 0.6726 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.84548\n",
      "Epoch 129/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5448 - acc: 0.8578 - val_loss: 0.7226 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.84548\n",
      "Epoch 130/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5495 - acc: 0.8543 - val_loss: 0.6860 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.84548\n",
      "Epoch 131/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5412 - acc: 0.8565 - val_loss: 0.7438 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.84548\n",
      "Epoch 132/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5506 - acc: 0.8559 - val_loss: 0.7675 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.84548\n",
      "Epoch 133/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5475 - acc: 0.8560 - val_loss: 0.7073 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.84548\n",
      "Epoch 134/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5459 - acc: 0.8542 - val_loss: 0.7443 - val_acc: 0.8392\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.84548\n",
      "Epoch 135/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5431 - acc: 0.8549 - val_loss: 0.7191 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.84548\n",
      "Epoch 136/200\n",
      "90422/90422 [==============================] - 39s 436us/step - loss: 0.5445 - acc: 0.8552 - val_loss: 0.6890 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.84548\n",
      "Epoch 137/200\n",
      "90422/90422 [==============================] - 39s 436us/step - loss: 0.5578 - acc: 0.8538 - val_loss: 0.6850 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.84548\n",
      "Epoch 138/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5434 - acc: 0.8557 - val_loss: 0.7602 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.84548\n",
      "Epoch 139/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5619 - acc: 0.8528 - val_loss: 0.6990 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.84548\n",
      "Epoch 140/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5515 - acc: 0.8552 - val_loss: 0.7130 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.84548\n",
      "Epoch 141/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5473 - acc: 0.8549 - val_loss: 0.7690 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.84548\n",
      "Epoch 142/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5573 - acc: 0.8532 - val_loss: 0.7243 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.84548\n",
      "Epoch 143/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5510 - acc: 0.8547 - val_loss: 0.7191 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.84548\n",
      "Epoch 144/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5507 - acc: 0.8545 - val_loss: 0.7051 - val_acc: 0.8294\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.84548\n",
      "Epoch 145/200\n",
      "90422/90422 [==============================] - 40s 438us/step - loss: 0.5445 - acc: 0.8563 - val_loss: 0.7834 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.84548\n",
      "Epoch 146/200\n",
      "90422/90422 [==============================] - 39s 437us/step - loss: 0.5460 - acc: 0.8563 - val_loss: 0.7115 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.84548\n",
      "Epoch 147/200\n",
      "90422/90422 [==============================] - 40s 437us/step - loss: 0.5521 - acc: 0.8557 - val_loss: 0.7305 - val_acc: 0.8283\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.84548\n",
      "Epoch 148/200\n",
      "90422/90422 [==============================] - 39s 436us/step - loss: 0.5558 - acc: 0.8535 - val_loss: 0.7187 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.84548\n",
      "Epoch 149/200\n",
      " 3500/90422 [>.............................] - ETA: 35s - loss: 0.5563 - acc: 0.8589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-04b833cd5a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, \n\u001b[0;32m---> 11\u001b[0;31m                     validation_data=(X_test, Y_test_hot), callbacks=callbacks_list, )\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf36/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = get_model(45)\n",
    "\n",
    "# checkpoint\n",
    "filepath=COMBINED_MODEL_SAVE_PATH + \"all_data-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, \n",
    "                    validation_data=(X_test, Y_test_hot), callbacks=callbacks_list, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model() missing 1 required positional argument: 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-93a984f117b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the model with the best val accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOMBINED_MODEL_SAVE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"all_data-81-0.85.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_model() missing 1 required positional argument: 'num_classes'"
     ]
    }
   ],
   "source": [
    "# loading the model with the best val accuracy\n",
    "model = get_model()\n",
    "weights_path = \"./models/model2b.hdf5\"\n",
    "model.load_weights(weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(COMBINED_MODEL_SAVE_PATH + 'model_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(COMBINED_MODEL_SAVE_PATH + 'model_loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test loss and scores respectively\n",
    "train_loss_score=model.evaluate(X_train,Y_train_hot)\n",
    "val_loss_score=model.evaluate(X_val,Y_val_hot)\n",
    "test_loss_score=model.evaluate(X_test,Y_test_hot)\n",
    "print(train_loss_score)\n",
    "print(val_loss_score)\n",
    "print(test_loss_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts one sample\n",
    "labels = ['down', 'learn', 'right', 'nine', 'eight', 'dog', 'bird', 'house',\n",
    " 'marvin', 'zero', 'sheila', 'bed', 'follow', 'off', 'happy', 'backward', 'on',\n",
    "  'cat', 'left', 'five', 'visual', 'one', 'no', 'two', 'yes', 'forward', 'tree',\n",
    "   'three', 'go', 'seven', 'six', 'wow', 'stop', 'four', 'up','air_conditioner',\n",
    "   'dog_bark', 'street_music', 'car_horn', 'drilling', 'children_playing',\n",
    "    'siren', 'engine_idling', 'jackhammer', 'gun_shot']\n",
    "\n",
    "def predict(filepath, model,labels):\n",
    "    mfcc = wav2mfcc(testFile, max_len=40)\n",
    "    mfcc_reshaped = mfcc.reshape(1,feature_dim_1,feature_dim_2,channel)\n",
    "    odds= model.predict(mfcc_reshaped)\n",
    "    odds_max = np.argmax(odds)\n",
    "    label = labels[odds_max]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = SPEECH_DATA_PATH + 'happy/27c30960_nohash_0.wav'\n",
    "print(predict(testFile,model,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
