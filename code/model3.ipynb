{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, CuDNNLSTM, LSTM, ConvLSTM2D, Bidirectional\n",
    "from keras.layers import GlobalMaxPooling2D , GlobalMaxPooling1D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_DATA_PATH = \"./speech/data/\"\n",
    "\n",
    "URBAN_NOISE_DATA_PATH = \"./urban/data/\"\n",
    "\n",
    "COMBINED_DATA_PATH = \"./combined/data/\"\n",
    "\n",
    "SPEECH_NPY_PATH = \"./40bins/npy/\"\n",
    "\n",
    "URBAN_NOISE_NPY_PATH = \"./40bins/npy/\"\n",
    "\n",
    "COMBINED_NPY_PATH =  \"./combined/40bins/npy/\"\n",
    "\n",
    "COMBINED_MODEL_SAVE_PATH = \"./models/40bins-model3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech test and val file paths\n",
    "testFile = \"./data/testing_list.txt\"\n",
    "valFile = \"./data/validation_list.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to convert wav file to mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to convert wav2mfcc\n",
    "# samp rate of the speech wav files is 16000\n",
    "# samp rate of the urban noise wav files is 8000\n",
    "# use the samprate argument to change that.... will downsample speech wav files to 8000 in the future to make it easier\n",
    "def wav2mfcc(file_path, max_len=11,samprate = 8000):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    ##mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=samprate)\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args: Folder Path\n",
    "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
    "# make sure the background noise folder is not insde the DATA_PATH. because that is used for data augmentation and not recognition\n",
    "def get_labels(path=COMBINED_DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to extract and save features from speech commands data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the save data code here....with test train and val split\n",
    "# make sure the background_noise folder is not in the path\n",
    "def save_data_speech(path = SPEECH_DATA_PATH, testFile = testFile, valFile = valFile, max_len = 11,savepath = SPEECH_NPY_PATH):\n",
    "\n",
    "    test_file = open(testFile, \"r\")\n",
    "    testFilesList = test_file.read().split('\\n')\n",
    "\n",
    "    val_file = open(valFile, \"r\")\n",
    "    valFilesList = val_file.read().split('\\n')\n",
    "\n",
    "    #print(testFilesList)\n",
    "    #print(valFilesList)\n",
    "    labels,_,_ = get_labels(path)\n",
    "    print(labels)\n",
    "    for label in labels:\n",
    "        mfcc_train = []\n",
    "        mfcc_test = []\n",
    "        mfcc_val = []\n",
    "        # saving a tuple of wavfile path and label/name format to compare in the test and val list\n",
    "        wavfiles = [(path + label + '/' + wavfile, label + '/' + wavfile)\n",
    "                    for wavfile in os.listdir(path + '/' + label)]\n",
    "        \n",
    "        #print(wavfiles)\n",
    "        \n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            #print(wavfile[0])\n",
    "            #print(wavfile[1])\n",
    "            mfcc = wav2mfcc(wavfile[0], max_len=max_len)\n",
    "            if wavfile[1] in testFilesList:\n",
    "                mfcc_test.append(mfcc)\n",
    "            elif wavfile[1] in valFilesList:\n",
    "                mfcc_val.append(mfcc)\n",
    "            else:\n",
    "                mfcc_train.append(mfcc)\n",
    "                \n",
    "        np.save(savepath + label + '_test.npy', mfcc_test)\n",
    "        np.save(savepath + label + '_val.npy', mfcc_val)\n",
    "        np.save(savepath + label + '_train.npy', mfcc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to extract and save features from urban sounds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just saving the urban data as the npy file.\n",
    "# will split the data into test train and val after loading the data nd the labels by using a test_train split function\n",
    "def save_urbanNoise_data(path = URBAN_NOISE_DATA_PATH, max_len = 11, savePath = URBAN_NOISE_NPY_PATH):\n",
    "    labels,_,_ = get_labels(path)\n",
    "    for label in labels:\n",
    "        mfccs = []\n",
    "        mfcc_train = []\n",
    "        mfcc_test = []\n",
    "        mfcc_val = []\n",
    "        print(label)\n",
    "        \n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        \n",
    "        for wavfile in tqdm(wavfiles, \"saving vectors of label - '{}'\".format(label)):\n",
    "            try:\n",
    "                mfcc = wav2mfcc(wavfile, max_len = max_len)\n",
    "                mfccs.append(mfcc)\n",
    "            except:\n",
    "                print(wavfile)\n",
    "        \n",
    "        np.save(savePath + label + '.npy', mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 40      #max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# speech data\n",
    "save_data_speech(max_len = feature_dim_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban Noise data\n",
    "save_urbanNoise_data(max_len = feature_dim_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the saved feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the urbanNoiseData along with their labels then split them into train,val and split and save as npy files\n",
    "# we will get all the data from all the classes append them into an array and then use a test train split function\n",
    "def getUrbanNoiseDataSplit(path = URBAN_NOISE_DATA_PATH, savePath = URBAN_NOISE_NPY_PATH, split_ratio=0.8,random_state = 42):\n",
    "    labels, indices, _ = get_labels(path)\n",
    "    # get the array for each label\n",
    "    X = np.load(savePath + labels[0] + '.npy')\n",
    "    Y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    # filling with i+1 in each loop so basically starting the class values from 0 to 9.\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(savePath + label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        Y = np.append(Y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(Y)\n",
    "    \n",
    "    # not shuffling the data for now. Will shuffle them while training\n",
    "    X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_temp,Y_temp, test_size = (1-split_ratio), random_state = random_state,shuffle = True)\n",
    "    \n",
    "    return labels,X_train,X_val,X_test,Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speech we already split the data into train test and val and then saved the data. \n",
    "# so now we just need to import the data and then append all the labels\n",
    "def getSpeechDataSplit(path = SPEECH_DATA_PATH, savePath = SPEECH_NPY_PATH):\n",
    "    \n",
    "    labels, indices, _ = get_labels(path)\n",
    "    # get the array for each label\n",
    "    X_train = np.load(savePath + labels[0] + '_train.npy')\n",
    "    Y_train = np.zeros(X_train.shape[0])\n",
    "    X_val = np.load(savePath + labels[0] + '_val.npy')\n",
    "    Y_val = np.zeros(X_val.shape[0])\n",
    "    X_test = np.load(savePath + labels[0] + '_test.npy')\n",
    "    Y_test = np.zeros(X_test.shape[0])\n",
    "    \n",
    "    for i,label in enumerate(labels[1:]):\n",
    "        x_train = np.load(savePath + label + '_train.npy')\n",
    "        x_val = np.load(savePath + label + '_val.npy')\n",
    "        x_test = np.load(savePath + label + '_test.npy')\n",
    "        X_train = np.vstack((X_train, x_train))\n",
    "        X_val = np.vstack((X_val, x_val))\n",
    "        X_test = np.vstack((X_test, x_test))\n",
    "        \n",
    "        Y_train = np.append(Y_train, np.full(x_train.shape[0],fill_value= (i+1)))\n",
    "        Y_val = np.append(Y_val, np.full(x_val.shape[0],fill_value= (i+1)))\n",
    "        Y_test = np.append(Y_test, np.full(x_test.shape[0],fill_value= (i+1)))\n",
    "    \n",
    "        \n",
    "    return labels,X_train,X_val,X_test,Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['air_conditioner', 'dog_bark', 'street_music', 'car_horn', 'drilling', 'children_playing', 'siren', 'engine_idling', 'jackhammer', 'gun_shot']\n"
     ]
    }
   ],
   "source": [
    "# # Loading train set and test set of urban Noise\n",
    "labels_un, X_train_un,X_val_un, X_test_un, Y_train_un,Y_val_un, Y_test_un = getUrbanNoiseDataSplit()\n",
    "print(labels_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'learn', 'right', 'nine', 'eight', 'dog', 'bird', 'house', 'marvin', 'zero', 'sheila', 'bed', 'follow', 'off', 'happy', 'backward', 'on', 'cat', 'left', 'five', 'visual', 'one', 'no', 'two', 'yes', 'forward', 'tree', 'three', 'go', 'seven', 'six', 'wow', 'stop', 'four', 'up']\n"
     ]
    }
   ],
   "source": [
    "# # Loading train set and test set of speech\n",
    "labels_sp, X_train_sp,X_val_sp, X_test_sp, Y_train_sp,Y_val_sp, Y_test_sp = getSpeechDataSplit()\n",
    "print(labels_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5587, 20, 40), (1397, 20, 40), (1746, 20, 40), (5587,), (1397,), (1746,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shapes of all arrays\n",
    "X_train_un.shape,X_val_un.shape, X_test_un.shape, Y_train_un.shape,Y_val_un.shape, Y_test_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84843, 20, 40), (9981, 20, 40), (11005, 20, 40), (84843,), (9981,), (11005,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sp.shape,X_val_sp.shape, X_test_sp.shape, Y_train_sp.shape,Y_val_sp.shape, Y_test_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "# if we want to combine both the samples we just need to add the Y sample with the numeber of labels in the previous dataset\n",
    "\n",
    "# combining samples\n",
    "labels = labels_sp + labels_un\n",
    "print(len(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add 35 to the urban Noise Y data to make them into the new labels\n",
    "\n",
    "\n",
    "Y_train_un_new = Y_train_un + 35\n",
    "Y_test_un_new = Y_test_un + 35\n",
    "Y_val_un_new = Y_val_un + 35\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90430,)\n",
      "(12751,)\n",
      "(11378,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.append(Y_train_sp, Y_train_un_new)\n",
    "Y_test = np.append(Y_test_sp, Y_test_un_new)\n",
    "Y_val = np.append(Y_val_sp, Y_val_un_new)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ... 39. 37. 35.]\n",
      "[ 0.  0.  0. ... 37. 38. 42.]\n",
      "[ 0.  0.  0. ... 39. 36. 41.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "print(Y_train)\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90430, 20, 40)\n",
      "(12751, 20, 40)\n",
      "(11378, 20, 40)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack((X_train_sp, X_train_un))\n",
    "X_test = np.vstack((X_test_sp, X_test_un))\n",
    "X_val = np.vstack((X_val_sp, X_val_un))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have combined data set and seperate datasets\n",
    "# X_train_un, X_test_un, X_val_un, Y_train_un, Y_test_un, Y_val_un ---urban Noise data - 10 clasees - (0-9)\n",
    "# X_train_sp, X_test_sp, X_val_sp, Y_train_sp, Y_test_sp, Y_val_sp --- speech data - 35 classes - (0-34)\n",
    "# X_train, X_test, X_val, Y_train, Y_test, Y_val --- combined dtat - 45 classes (0-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 200\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 45    #keeps changing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to perform 2D convolution\n",
    "# all data\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_val = X_val.reshape(X_val.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "Y_train_hot = to_categorical(Y_train)\n",
    "Y_val_hot = to_categorical(Y_val)\n",
    "Y_test_hot = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to perform 2D convolution\n",
    "# all data\n",
    "\n",
    "X_train_un = X_train_un.reshape(X_train_un.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_val_un = X_val_un.reshape(X_val_un.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test_un = X_test_un.reshape(X_test_un.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "Y_train_un_hot = to_categorical(Y_train_un)\n",
    "Y_val_un_hot = to_categorical(Y_val_un)\n",
    "Y_test_un_hot = to_categorical(Y_test_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to perform 2D convolution\n",
    "# all data\n",
    "\n",
    "X_train_sp = X_train_sp.reshape(X_train_sp.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_val_sp = X_val_sp.reshape(X_val_sp.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test_sp = X_test_sp.reshape(X_test_sp.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "Y_train_sp_hot = to_categorical(Y_train_sp)\n",
    "Y_val_sp_hot = to_categorical(Y_val_sp)\n",
    "Y_test_sp_hot = to_categorical(Y_test_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90430, 20, 40, 1)\n",
      "(12751, 20, 40, 1)\n",
      "(11378, 20, 40, 1)\n",
      "(90430, 45)\n",
      "(12751, 45)\n",
      "(11378, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "print(Y_train_hot.shape)\n",
    "print(Y_test_hot.shape)\n",
    "print(Y_val_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 19, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 19, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 18, 38, 48)        6192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 38, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 38, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 17, 37, 120)       23160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 17, 37, 120)       480       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 17, 37, 120)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 18, 120)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8, 18, 120)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 17, 120)        57720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 17, 120)        480       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 17, 120)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 16, 120)        57720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 16, 120)        480       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 16, 120)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               368768    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 45)                2925      \n",
      "=================================================================\n",
      "Total params: 526,661\n",
      "Trainable params: 525,781\n",
      "Non-trainable params: 880\n",
      "_________________________________________________________________\n",
      "Train on 90430 samples, validate on 11378 samples\n",
      "Epoch 1/200\n",
      "90430/90430 [==============================] - 424s 5ms/step - loss: 3.0936 - acc: 0.1318 - val_loss: 2.3498 - val_acc: 0.2701\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27008, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-01-0.27.hdf5\n",
      "Epoch 2/200\n",
      "90430/90430 [==============================] - 426s 5ms/step - loss: 2.0228 - acc: 0.3877 - val_loss: 1.3541 - val_acc: 0.5778\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27008 to 0.57778, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-02-0.58.hdf5\n",
      "Epoch 3/200\n",
      "90430/90430 [==============================] - 428s 5ms/step - loss: 1.5456 - acc: 0.5375 - val_loss: 1.0978 - val_acc: 0.6676\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.57778 to 0.66760, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-03-0.67.hdf5\n",
      "Epoch 4/200\n",
      "90430/90430 [==============================] - 426s 5ms/step - loss: 1.3125 - acc: 0.6131 - val_loss: 1.0111 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66760 to 0.69353, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-04-0.69.hdf5\n",
      "Epoch 5/200\n",
      "90430/90430 [==============================] - 417s 5ms/step - loss: 1.1710 - acc: 0.6604 - val_loss: 0.8386 - val_acc: 0.7443\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.69353 to 0.74433, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-05-0.74.hdf5\n",
      "Epoch 6/200\n",
      "90430/90430 [==============================] - 416s 5ms/step - loss: 1.0767 - acc: 0.6902 - val_loss: 0.8589 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74433\n",
      "Epoch 7/200\n",
      "90430/90430 [==============================] - 416s 5ms/step - loss: 1.0054 - acc: 0.7116 - val_loss: 0.7681 - val_acc: 0.7674\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74433 to 0.76745, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-07-0.77.hdf5\n",
      "Epoch 8/200\n",
      "90430/90430 [==============================] - 419s 5ms/step - loss: 0.9536 - acc: 0.7257 - val_loss: 0.7205 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.76745 to 0.78775, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-08-0.79.hdf5\n",
      "Epoch 9/200\n",
      "90430/90430 [==============================] - 425s 5ms/step - loss: 0.9096 - acc: 0.7401 - val_loss: 0.7187 - val_acc: 0.7845\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78775\n",
      "Epoch 10/200\n",
      "90430/90430 [==============================] - 419s 5ms/step - loss: 0.8713 - acc: 0.7493 - val_loss: 0.6987 - val_acc: 0.7934\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.78775 to 0.79337, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-10-0.79.hdf5\n",
      "Epoch 11/200\n",
      "90430/90430 [==============================] - 423s 5ms/step - loss: 0.8476 - acc: 0.7591 - val_loss: 0.6555 - val_acc: 0.8057\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79337 to 0.80568, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-11-0.81.hdf5\n",
      "Epoch 12/200\n",
      "90430/90430 [==============================] - 416s 5ms/step - loss: 0.8206 - acc: 0.7682 - val_loss: 0.6455 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80568 to 0.80805, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-12-0.81.hdf5\n",
      "Epoch 13/200\n",
      "90430/90430 [==============================] - 415s 5ms/step - loss: 0.7972 - acc: 0.7738 - val_loss: 0.6331 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.80805 to 0.81332, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-13-0.81.hdf5\n",
      "Epoch 14/200\n",
      "90430/90430 [==============================] - 415s 5ms/step - loss: 0.7760 - acc: 0.7820 - val_loss: 0.6306 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.81332 to 0.81921, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-14-0.82.hdf5\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.7566 - acc: 0.7867 - val_loss: 0.6549 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81921\n",
      "Epoch 16/200\n",
      "90430/90430 [==============================] - 413s 5ms/step - loss: 0.7427 - acc: 0.7910 - val_loss: 0.7027 - val_acc: 0.8027\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81921\n",
      "Epoch 17/200\n",
      "90430/90430 [==============================] - 413s 5ms/step - loss: 0.7291 - acc: 0.7943 - val_loss: 0.5940 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.81921 to 0.83108, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-17-0.83.hdf5\n",
      "Epoch 18/200\n",
      "90430/90430 [==============================] - 407s 5ms/step - loss: 0.7149 - acc: 0.7995 - val_loss: 0.5977 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.83108 to 0.83169, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-18-0.83.hdf5\n",
      "Epoch 19/200\n",
      "90430/90430 [==============================] - 407s 5ms/step - loss: 0.7046 - acc: 0.7989 - val_loss: 0.6299 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.83169\n",
      "Epoch 20/200\n",
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.6898 - acc: 0.8072 - val_loss: 0.5916 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.83169 to 0.83556, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-20-0.84.hdf5\n",
      "Epoch 21/200\n",
      "90430/90430 [==============================] - 412s 5ms/step - loss: 0.6774 - acc: 0.8090 - val_loss: 0.5760 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.83556 to 0.83679, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-21-0.84.hdf5\n",
      "Epoch 22/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.6650 - acc: 0.8125 - val_loss: 0.5786 - val_acc: 0.8350\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.83679\n",
      "Epoch 23/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.6615 - acc: 0.8133 - val_loss: 0.6540 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.83679\n",
      "Epoch 24/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.6491 - acc: 0.8178 - val_loss: 0.5776 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.83679 to 0.83820, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-24-0.84.hdf5\n",
      "Epoch 25/200\n",
      "90430/90430 [==============================] - 412s 5ms/step - loss: 0.6420 - acc: 0.8200 - val_loss: 0.5692 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.83820 to 0.84127, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-25-0.84.hdf5\n",
      "Epoch 26/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.6333 - acc: 0.8228 - val_loss: 0.6000 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.84127\n",
      "Epoch 27/200\n",
      "90430/90430 [==============================] - 407s 5ms/step - loss: 0.6270 - acc: 0.8253 - val_loss: 0.5504 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.84127 to 0.84488, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-27-0.84.hdf5\n",
      "Epoch 28/200\n",
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.6227 - acc: 0.8256 - val_loss: 0.6103 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.84488\n",
      "Epoch 29/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.6139 - acc: 0.8270 - val_loss: 0.5685 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.84488 to 0.84567, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-29-0.85.hdf5\n",
      "Epoch 30/200\n",
      "90430/90430 [==============================] - 410s 5ms/step - loss: 0.6049 - acc: 0.8292 - val_loss: 0.5667 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.84567\n",
      "Epoch 31/200\n",
      "90430/90430 [==============================] - 408s 5ms/step - loss: 0.6023 - acc: 0.8313 - val_loss: 0.5675 - val_acc: 0.8433\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.84567\n",
      "Epoch 32/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.5956 - acc: 0.8325 - val_loss: 0.5645 - val_acc: 0.8422\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.1.\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.84567\n",
      "Epoch 33/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.5373 - acc: 0.8471 - val_loss: 0.5336 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.84567 to 0.85533, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-33-0.86.hdf5\n",
      "Epoch 34/200\n",
      "90430/90430 [==============================] - 410s 5ms/step - loss: 0.5121 - acc: 0.8551 - val_loss: 0.5340 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.85533\n",
      "Epoch 35/200\n",
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.5053 - acc: 0.8572 - val_loss: 0.5328 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.85533 to 0.85683, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-35-0.86.hdf5\n",
      "Epoch 36/200\n",
      "90430/90430 [==============================] - 404s 4ms/step - loss: 0.5030 - acc: 0.8577 - val_loss: 0.5357 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.85683 to 0.85780, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-36-0.86.hdf5\n",
      "Epoch 37/200\n",
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.5043 - acc: 0.8573 - val_loss: 0.5379 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.85780\n",
      "Epoch 38/200\n",
      "90430/90430 [==============================] - 411s 5ms/step - loss: 0.4972 - acc: 0.8589 - val_loss: 0.5348 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.85780\n",
      "Epoch 39/200\n",
      "90430/90430 [==============================] - 409s 5ms/step - loss: 0.4897 - acc: 0.8615 - val_loss: 0.5355 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.85780 to 0.85850, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-39-0.86.hdf5\n",
      "Epoch 40/200\n",
      "90430/90430 [==============================] - 406s 4ms/step - loss: 0.4829 - acc: 0.8610 - val_loss: 0.5369 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85850\n",
      "Epoch 41/200\n",
      "90430/90430 [==============================] - 406s 4ms/step - loss: 0.4844 - acc: 0.8622 - val_loss: 0.5344 - val_acc: 0.8589\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.85850 to 0.85885, saving model to /media/tintin/3bde46c1-cca7-4db6-b2ca-e71397572866/tintin/speech-urban-data/combined/40_2blocks_updateLr_batchNorm/all_data-41-0.86.hdf5\n",
      "Epoch 42/200\n",
      "90430/90430 [==============================] - 407s 5ms/step - loss: 0.4876 - acc: 0.8620 - val_loss: 0.5362 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85885\n",
      "Epoch 43/200\n",
      "90430/90430 [==============================] - 406s 4ms/step - loss: 0.4877 - acc: 0.8613 - val_loss: 0.5362 - val_acc: 0.8582\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.85885\n",
      "Epoch 44/200\n",
      "90430/90430 [==============================] - 406s 4ms/step - loss: 0.4872 - acc: 0.8618 - val_loss: 0.5352 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.85885\n",
      "Epoch 45/200\n",
      "90430/90430 [==============================] - 406s 4ms/step - loss: 0.4842 - acc: 0.8621 - val_loss: 0.5356 - val_acc: 0.8586\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.85885\n",
      "Epoch 00045: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "# checkpoint\n",
    "filepath=  \"./models/model3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlyStoppping = EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5,verbose=1,epsilon=0.001,min_lr=1e-5)\n",
    "callbacks_list = [earlyStoppping, reduceLR, checkpoint]\n",
    "\n",
    "history = model.fit(X_train, Y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, \n",
    "                    validation_data=(X_val, Y_val_hot), callbacks=callbacks_list, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tintin/miniconda3/envs/tf36/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 19, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 19, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 19, 39, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 38, 48)        6192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 18, 38, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 18, 38, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 37, 120)       23160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 37, 120)       480       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 37, 120)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 18, 120)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 18, 120)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 17, 120)        57720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 17, 120)        480       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 17, 120)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 16, 120)        57720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 16, 120)        480       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6, 16, 120)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 8, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               368768    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 45)                2925      \n",
      "=================================================================\n",
      "Total params: 526,661\n",
      "Trainable params: 525,781\n",
      "Non-trainable params: 880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading the model with the best val accuracy\n",
    "model = get_model()\n",
    "weights_path = \"./models/model3.hdf5\"\n",
    "model.load_weights(weights_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(COMBINED_MODEL_SAVE_PATH + 'model_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(COMBINED_MODEL_SAVE_PATH + 'model_loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90430/90430 [==============================] - 114s 1ms/step\n",
      "11378/11378 [==============================] - 12s 1ms/step\n",
      "12751/12751 [==============================] - 14s 1ms/step\n",
      "[0.23867406456338977, 0.9291496184802116]\n",
      "[0.5344296225000714, 0.8588504130883468]\n",
      "[0.6031765448477734, 0.8386008940568747]\n"
     ]
    }
   ],
   "source": [
    "#train and test loss and scores respectively\n",
    "train_loss_score=model.evaluate(X_train,Y_train_hot)\n",
    "val_loss_score=model.evaluate(X_val,Y_val_hot)\n",
    "test_loss_score=model.evaluate(X_test,Y_test_hot)\n",
    "print(train_loss_score)\n",
    "print(val_loss_score)\n",
    "print(test_loss_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts one sample\n",
    "labels = ['down', 'learn', 'right', 'nine', 'eight', 'dog', 'bird', 'house',\n",
    " 'marvin', 'zero', 'sheila', 'bed', 'follow', 'off', 'happy', 'backward', 'on',\n",
    "  'cat', 'left', 'five', 'visual', 'one', 'no', 'two', 'yes', 'forward', 'tree',\n",
    "   'three', 'go', 'seven', 'six', 'wow', 'stop', 'four', 'up','air_conditioner',\n",
    "   'dog_bark', 'street_music', 'car_horn', 'drilling', 'children_playing',\n",
    "    'siren', 'engine_idling', 'jackhammer', 'gun_shot']\n",
    "\n",
    "def predict(filepath, model,labels):\n",
    "    mfcc = wav2mfcc(testFile, max_len=40)\n",
    "    mfcc_reshaped = mfcc.reshape(1,feature_dim_1,feature_dim_2,channel)\n",
    "    odds= model.predict(mfcc_reshaped)\n",
    "    odds_max = np.argmax(odds)\n",
    "    label = labels[odds_max]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = SPEECH_DATA_PATH + 'happy/27c30960_nohash_0.wav'\n",
    "print(predict(testFile,model,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "feature_dim_2 = 15      #max_len\n",
    "feature_dim_1 = 20\n",
    "channel=1\n",
    "num_classes=45\n",
    "#max_len\n",
    "model = get_model()\n",
    "plot_model(model, show_shapes = True, show_layer_names = True,to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
